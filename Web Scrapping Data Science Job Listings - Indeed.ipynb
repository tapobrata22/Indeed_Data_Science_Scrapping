{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's a great time to be a data scientist entering the job market. That's according to the recent data from job sites Indeed and Dice.\n",
    "\n",
    "## \"The job of a data scientist has only grown sexier,\" said Andrew Flowers, an economist at Indeed, based in Austin, Texas, and author of the Indeed report. \"More employers than ever are looking to hire data scientists.\"\n",
    "\n",
    "These words are not mine; rather they have been copied from one of those countless articles which glorify the future of data scientists. With my curiosity piqued, I decided to scrape the job listings from Indeed.com in order to better understand the roles and minimum qualifications for Data Scientists across the major cities of America.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took me close to 24 hours to write the entire scrapping code on Python and test it multiple times in order to ensure that the process can be swiftly automated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code can entract 800 Data Science jobs across USA within 20 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import random \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from pandas import ExcelWriter\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mentioning the Cities for which the Data Science Jobs will be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science Job Listings will be extracted for-  ['Philadelphia', 'San+Francisco', 'New+York', 'California', 'Houston', 'Boston', 'Chicago', 'Seattle', 'Austin', 'Maryland']\n"
     ]
    }
   ],
   "source": [
    "city_list = ['Philadelphia','San+Francisco', 'New+York', 'California', 'Houston', 'Boston', 'Chicago', 'Seattle', 'Austin', 'Maryland']\n",
    "print(\"Data Science Job Listings will be extracted for- \", city_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since multiple cities and multiple web-pages are involved, a for-loop within a for loop have been written to take care of the automation. For better explainability, I am taking a static example and explaining the entire scrapping process. Refer to the last cell for the full code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data Science Job Postings for - Philadelphia from the link -  https://www.indeed.com/jobs?q=data+scientist+$65,000&l=Philadelphia&start=10\n"
     ]
    }
   ],
   "source": [
    "#Mentioning the city_name and html link from where the daat will be scrapped\n",
    "city_name = city_list[0]\n",
    "\n",
    "original_html = 'https://www.indeed.com/jobs?q=data+scientist+$65,000&l='+city_name+'&start=10'\n",
    "#Parsing the html using beautiful soup and store in variable 'soup'\n",
    "urlpage =  str(original_html)\n",
    "page = urllib.request.urlopen(urlpage)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "print(\"Extracting Data Science Job Postings for -\", city_name, \"from the link - \", urlpage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop to extract job roles and link of job-descriptions present on page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Roles present on this page are -  ['Senior Data Scientist', 'Epidemiologist/Data Scientist', 'Data Scientist', 'SR DATA SCIENTIST', 'Data Scientist - Forecasting', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Quantitative Research Analyst', 'Senior Principal Scientist, Genetic Data Integration']\n"
     ]
    }
   ],
   "source": [
    "all_links = []\n",
    "all_roles = []\n",
    "role_list = soup.findAll('div', attrs={'class':'title'})\n",
    "for i in range(0,len(role_list)):\n",
    "    #i = 0\n",
    "    s = str(role_list[i])\n",
    "    start = 'href='\n",
    "    end = ' id='\n",
    "    link = s[s.find(start)+len(start):s.rfind(end)]\n",
    "    link = link.replace('\"', \"\")\n",
    "    all_links.append(link)\n",
    "    title_name = str(role_list[i].text)\n",
    "    title_name = title_name.strip()\n",
    "    all_roles.append(title_name)\n",
    "    \n",
    "print(\"Job Roles present on this page are - \", all_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/rc/clk?jk=4be3251985c5e00f&amp;fccid=a8656bc4f87322ca&amp;vjs=3',\n",
       " '/rc/clk?jk=5478fd9dd29db409&amp;fccid=0b53dbe3f694023a&amp;vjs=3',\n",
       " '/rc/clk?jk=85204fc1a1d3b305&amp;fccid=733a6a4b0db0cb79&amp;vjs=3',\n",
       " '/rc/clk?jk=b8946db7aad572ee&amp;fccid=0bed8e17bc113980&amp;vjs=3',\n",
       " '/rc/clk?jk=67a1dad2fca55e88&amp;fccid=8a2222c2ef6a251d&amp;vjs=3',\n",
       " '/rc/clk?jk=5f7754112b09e4ac&amp;fccid=ef670f88bdb8a879&amp;vjs=3',\n",
       " '/rc/clk?jk=6b4ec424a41a8ee9&amp;fccid=4c3bc2bd3fda6e72&amp;vjs=3',\n",
       " '/rc/clk?jk=f6c3ef61212721db&amp;fccid=b5f5a475a9aae6da&amp;vjs=3',\n",
       " '/rc/clk?jk=efc24bae038b232d&amp;fccid=87e87705f46fa7bc&amp;vjs=3',\n",
       " '/rc/clk?jk=7672f73f905b6dde&amp;fccid=0bed8e17bc113980&amp;vjs=3']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After testing the elements of all_links, I realized that some text manipulation needs to be done with them in order to obtain the proper HTML links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.indeed.com/viewjob??jk=4be3251985c5e00f&amp;fccid=a8656bc4f87322ca&amp;vjs=3', 'https://www.indeed.com/viewjob??jk=5478fd9dd29db409&amp;fccid=0b53dbe3f694023a&amp;vjs=3', 'https://www.indeed.com/viewjob??jk=85204fc1a1d3b305&amp;fccid=733a6a4b0db0cb79&amp;vjs=3', 'https://www.indeed.com/viewjob??jk=b8946db7aad572ee&amp;fccid=0bed8e17bc113980&amp;vjs=3', 'https://www.indeed.com/viewjob??jk=67a1dad2fca55e88&amp;fccid=8a2222c2ef6a251d&amp;vjs=3', 'https://www.indeed.com/viewjob??jk=5f7754112b09e4ac&amp;fccid=ef670f88bdb8a879&amp;vjs=3', 'https://www.indeed.com/viewjob??jk=6b4ec424a41a8ee9&amp;fccid=4c3bc2bd3fda6e72&amp;vjs=3', 'https://www.indeed.com/viewjob??jk=f6c3ef61212721db&amp;fccid=b5f5a475a9aae6da&amp;vjs=3', 'https://www.indeed.com/viewjob??jk=efc24bae038b232d&amp;fccid=87e87705f46fa7bc&amp;vjs=3', 'https://www.indeed.com/viewjob??jk=7672f73f905b6dde&amp;fccid=0bed8e17bc113980&amp;vjs=3']\n"
     ]
    }
   ],
   "source": [
    "all_podcast_links = all_links\n",
    "all_podcast_links = [i.split('-')[-1] for i in all_podcast_links]\n",
    "\n",
    "modified_links = []\n",
    "for i in range(0,len(all_podcast_links)):\n",
    "    main_link_text = all_podcast_links[i]\n",
    "    string_find = '/rc/clk'\n",
    "    if(main_link_text.find(string_find) == -1):\n",
    "        main_link_text = '/rc/clk?jk=' + main_link_text\n",
    "        text_replace = \"?fccid=\"\n",
    "        main_link_text = main_link_text.replace(text_replace, '&amp;fccid=')\n",
    "        print('Link modified for link number', i)\n",
    "    else:\n",
    "        main_link_text = main_link_text\n",
    "    modified_links.append(main_link_text)\n",
    "\n",
    "text_delete = '/rc/clk'\n",
    "all_podcast_links = [w.replace(text_delete,\"\") for w in modified_links]\n",
    "text_replace = \"/jobs/\"\n",
    "all_podcast_links = [w.replace(text_replace,\"&t=\") for w in all_podcast_links]\n",
    "text_to_add = 'https://www.indeed.com/viewjob?'\n",
    "final_links = [text_to_add+s for s in all_podcast_links]\n",
    "text_replace = \"/viewjob?/company/\"\n",
    "final_links = [w.replace(text_replace,\"/company/\") for w in final_links]\n",
    "print(final_links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above exercise of manipulating the text in order to obtain the correct HTML Link of the job descriptions took close to 2-3 hours because of the various formats present on the website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting names of all companies present on the web-page  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies present on the page - ['TDI Technologies Inc', 'NMS Labs', 'MCKEAN DEFENSE/CABRILLO TECHNOLOGIES', 'Johnson & Johnson Family of Companies', 'goPuff', 'Aramark', 'Social Science Research Solutions (SSRS)', 'RS Energy Group', 'STEVENS CAPITAL MANAGEMENT', 'Johnson & Johnson Family of Companies']\n"
     ]
    }
   ],
   "source": [
    "all_companies = []\n",
    "company_list = soup.findAll('span', attrs={'class':'company'})\n",
    "for i in range(0,len(company_list)):\n",
    "    #i = 2\n",
    "    comp_name = str(company_list[i].text)\n",
    "    comp_name = comp_name.strip()\n",
    "    all_companies.append(comp_name)\n",
    "    \n",
    "print(\"Companies present on the page -\", all_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting locations of all companies present on the web-page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Company Locations - ['Philadelphia, PA 19112 (Marconi Plaza-Packer Park area)', 'Willow Grove, PA', 'Philadelphia, PA', 'Spring House, PA', 'Philadelphia, PA', 'Philadelphia, PA 19107 (City Center East area)', 'Glen Mills, PA', 'Conshohocken, PA', 'Philadelphia, PA', 'Spring House, PA 19002']\n"
     ]
    }
   ],
   "source": [
    "all_locations = []\n",
    "location_list = soup.findAll('span', attrs={'class':'location accessible-contrast-color-location'})\n",
    "for i in range(0,len(location_list)):\n",
    "    #i = 2\n",
    "    loc_name = str(location_list[i].text)\n",
    "    loc_name = loc_name.strip()\n",
    "    all_locations.append(loc_name)\n",
    "    \n",
    "print(\"List of Company Locations -\", all_locations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting job summary of all companies present on the web-page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the job summary -  Is seeking candidates for a Senior Data Scientist position.The position’s main responsibility will be to gather, format, and analyze information from Navy Hull…\n"
     ]
    }
   ],
   "source": [
    "all_job_summary = []\n",
    "job_summary_list = soup.findAll('div', attrs={'class':'summary'})\n",
    "for i in range(0,len(location_list)):\n",
    "    #i = 2\n",
    "    job_summary = str(job_summary_list[i].text)\n",
    "    job_summary = job_summary.strip()\n",
    "    all_job_summary.append(job_summary)\n",
    "    \n",
    "print(\"One of the job summary - \", all_job_summary[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collating all the results into one dataframe for proper viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>Job_Summary</th>\n",
       "      <th>Location</th>\n",
       "      <th>JD_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TDI Technologies Inc</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Is seeking candidates for a Senior Data Scient...</td>\n",
       "      <td>Philadelphia, PA 19112 (Marconi Plaza-Packer P...</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=4be3251985c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NMS Labs</td>\n",
       "      <td>Epidemiologist/Data Scientist</td>\n",
       "      <td>The Center for Forensic Science Research and E...</td>\n",
       "      <td>Willow Grove, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=5478fd9dd29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCKEAN DEFENSE/CABRILLO TECHNOLOGIES</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>McKean Defense is a Naval Life Cycle Managemen...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=85204fc1a1d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Johnson &amp; Johnson Family of Companies</td>\n",
       "      <td>SR DATA SCIENTIST</td>\n",
       "      <td>Janssen Research &amp; Development is a world-clas...</td>\n",
       "      <td>Spring House, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=b8946db7aad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goPuff</td>\n",
       "      <td>Data Scientist - Forecasting</td>\n",
       "      <td>Are you passionate about forecasting?Do you de...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=67a1dad2fca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aramark</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>About The Data Science Group.The Data Science ...</td>\n",
       "      <td>Philadelphia, PA 19107 (City Center East area)</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=5f7754112b0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Social Science Research Solutions (SSRS)</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SSRS, a leading data-driven survey research an...</td>\n",
       "      <td>Glen Mills, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=6b4ec424a41...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Company_Name                           Role  \\\n",
       "0                      TDI Technologies Inc          Senior Data Scientist   \n",
       "1                                  NMS Labs  Epidemiologist/Data Scientist   \n",
       "2      MCKEAN DEFENSE/CABRILLO TECHNOLOGIES                 Data Scientist   \n",
       "3     Johnson & Johnson Family of Companies              SR DATA SCIENTIST   \n",
       "4                                    goPuff   Data Scientist - Forecasting   \n",
       "5                                   Aramark                 Data Scientist   \n",
       "6  Social Science Research Solutions (SSRS)                 Data Scientist   \n",
       "\n",
       "                                         Job_Summary  \\\n",
       "0  Is seeking candidates for a Senior Data Scient...   \n",
       "1  The Center for Forensic Science Research and E...   \n",
       "2  McKean Defense is a Naval Life Cycle Managemen...   \n",
       "3  Janssen Research & Development is a world-clas...   \n",
       "4  Are you passionate about forecasting?Do you de...   \n",
       "5  About The Data Science Group.The Data Science ...   \n",
       "6  SSRS, a leading data-driven survey research an...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Philadelphia, PA 19112 (Marconi Plaza-Packer P...   \n",
       "1                                   Willow Grove, PA   \n",
       "2                                   Philadelphia, PA   \n",
       "3                                   Spring House, PA   \n",
       "4                                   Philadelphia, PA   \n",
       "5     Philadelphia, PA 19107 (City Center East area)   \n",
       "6                                     Glen Mills, PA   \n",
       "\n",
       "                                             JD_Link  \n",
       "0  https://www.indeed.com/viewjob??jk=4be3251985c...  \n",
       "1  https://www.indeed.com/viewjob??jk=5478fd9dd29...  \n",
       "2  https://www.indeed.com/viewjob??jk=85204fc1a1d...  \n",
       "3  https://www.indeed.com/viewjob??jk=b8946db7aad...  \n",
       "4  https://www.indeed.com/viewjob??jk=67a1dad2fca...  \n",
       "5  https://www.indeed.com/viewjob??jk=5f7754112b0...  \n",
       "6  https://www.indeed.com/viewjob??jk=6b4ec424a41...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_company_df = pd.DataFrame(\n",
    "            {'Company_Name': all_companies,'Role': all_roles,'Job_Summary': all_job_summary,\n",
    "             'Location' :all_locations, 'JD_Link' :final_links\n",
    "            })\n",
    "\n",
    "full_company_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting full job description from the JD_Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD extracted for  1 companies out of - 10\n",
      "JD extracted for  2 companies out of - 10\n",
      "JD extracted for  3 companies out of - 10\n",
      "JD extracted for  4 companies out of - 10\n",
      "JD extracted for  5 companies out of - 10\n",
      "JD extracted for  6 companies out of - 10\n",
      "JD extracted for  7 companies out of - 10\n",
      "JD extracted for  8 companies out of - 10\n",
      "JD extracted for  9 companies out of - 10\n",
      "JD extracted for  10 companies out of - 10\n"
     ]
    }
   ],
   "source": [
    "all_company_df = pd.DataFrame()\n",
    "for i in range(0, len(full_company_df)):\n",
    "    #i = 0\n",
    "    new_link = full_company_df['JD_Link'][i]\n",
    "    urlpage =  str(new_link)\n",
    "    page = urllib.request.urlopen(urlpage)\n",
    "    # parse the html using beautiful soup and store in variable 'soup'\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    script = soup.find('script')\n",
    "    \n",
    "    #Extracting full JD from the respective div field\n",
    "    divs = soup.find_all('div',attrs={\"id\" : \"jobDescriptionText\"})\n",
    "    for d in divs:\n",
    "        job_description = str(d.text)\n",
    "        \n",
    "    #Creating master_Dataframe\n",
    "\n",
    "    master_df = pd.DataFrame({'JD_Link' : urlpage, 'job_description' : job_description}, index = [0])\n",
    "    all_company_df = all_company_df.append(master_df)\n",
    "    print('JD extracted for ', (i+1), \"companies out of -\", len(full_company_df))\n",
    "    \n",
    "all_company_df = all_company_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TDI Technologies, Inc. is seeking candidates for a Senior Data Scientist position. The position’s main responsibility will be to gather, format, and analyze information from Navy Hull, Mechanical, and Electrical (HM&E) systems. The position will require knowledge of machine learning methods and tools, as well as techniques such as natural language processing (NLP) and Optical Character Recognition (OCR). Candidates should be comfortable leading an engineering team, designing new software solutions, and interfacing with customers.\\nPRINCIPAL DUTIES/RESPONSIBILITIES:\\n1. Develop and test software, using Python and/or Java, to provide statistical analysis for various shipboard systems.\\n2. Lead a team in designing software solutions and pipelines that solve our customer’s data analytics challenges.\\n3. Prototype and demonstrate TDI Technologies’ data science capabilities to perspective customers.\\nEDUCATION AND EXPERIENCE REQUIREMENTS:\\n1. Bachelor of Science Degree in an engineering discipline - Computer Engineering, Electrical Engineering, Mechanical Engineering, Software Engineering or Computer Science is required\\n2. Fluent with scripting in Python\\n3. Strong management skills\\n4. 3-7 years of experience in a data science role\\nSPECIAL REQUIREMENTS:\\n1. Successful applicants must either have an active government security clearance or the ability to receive approval upon position acceptance.\\n2. Must have a valid US passport or the ability to obtain one upon position acceptance.\\nSKILLS AND ABILITIES:\\nEssential Skills:\\n1. Software development in Java\\n2. Software development in Python\\n3. Experience with machine learning and/or artificial intelligence\\n4. Experience with at least one of the following problem types: Time-series classification, regression analysis, optimization, clustering\\n5. Software development and operation within Linux and Unix based systems\\n6. Experience managing software baselines using version control tools such as SubVersion or Git\\n7. Strong technical writing skills and attention to detail for documentation\\n8. Willingness to lead a team and convey technical problems and solutions to a variety of team members\\nAdditional Preferred Skills:\\n1. Experience with one or more of the following: Natural Language Processing (NLP), Optical Character Recognition (OCR), Selenium, Beautiful Soup\\n2. Experience with machine learning tools and frameworks, including TensorFlow, scikit-learn, Pandas, and NumPy\\n3. Experience with rotating machinery and/or vibrations analysis\\nTravel:\\nThis position may require up to approximately 10% travel.\\n\\nLocation:\\nPhiladelphia, PA\\n\\nEqual Employment Opportunity Policy:\\nTDI Technologies, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type.\\nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layout, recall, transfer, leaves of absence, compensation and training.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_company_df['job_description'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping the Job Descriptions DataFrame with the originally obtained Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>Job_Summary</th>\n",
       "      <th>Location</th>\n",
       "      <th>JD_Link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TDI Technologies Inc</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Is seeking candidates for a Senior Data Scient...</td>\n",
       "      <td>Philadelphia, PA 19112 (Marconi Plaza-Packer P...</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=4be3251985c...</td>\n",
       "      <td>TDI Technologies, Inc. is seeking candidates f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NMS Labs</td>\n",
       "      <td>Epidemiologist/Data Scientist</td>\n",
       "      <td>The Center for Forensic Science Research and E...</td>\n",
       "      <td>Willow Grove, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=5478fd9dd29...</td>\n",
       "      <td>Title: Epidemiologist/ Data Scientist\\n\\nDepar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCKEAN DEFENSE/CABRILLO TECHNOLOGIES</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>McKean Defense is a Naval Life Cycle Managemen...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=85204fc1a1d...</td>\n",
       "      <td>McKean Defense is a Naval Life Cycle Managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Johnson &amp; Johnson Family of Companies</td>\n",
       "      <td>SR DATA SCIENTIST</td>\n",
       "      <td>Janssen Research &amp; Development is a world-clas...</td>\n",
       "      <td>Spring House, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=b8946db7aad...</td>\n",
       "      <td>Janssen Research &amp; Development is a world-clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goPuff</td>\n",
       "      <td>Data Scientist - Forecasting</td>\n",
       "      <td>Are you passionate about forecasting?Do you de...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=67a1dad2fca...</td>\n",
       "      <td>Are you passionate about forecasting? Do you d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aramark</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>About The Data Science Group.The Data Science ...</td>\n",
       "      <td>Philadelphia, PA 19107 (City Center East area)</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=5f7754112b0...</td>\n",
       "      <td>Description\\nAbout The Data Science Group\\nThe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Social Science Research Solutions (SSRS)</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SSRS, a leading data-driven survey research an...</td>\n",
       "      <td>Glen Mills, PA</td>\n",
       "      <td>https://www.indeed.com/viewjob??jk=6b4ec424a41...</td>\n",
       "      <td>SSRS Data Scientist\\nSSRS, a leading data-driv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Company_Name                           Role  \\\n",
       "0                      TDI Technologies Inc          Senior Data Scientist   \n",
       "1                                  NMS Labs  Epidemiologist/Data Scientist   \n",
       "2      MCKEAN DEFENSE/CABRILLO TECHNOLOGIES                 Data Scientist   \n",
       "3     Johnson & Johnson Family of Companies              SR DATA SCIENTIST   \n",
       "4                                    goPuff   Data Scientist - Forecasting   \n",
       "5                                   Aramark                 Data Scientist   \n",
       "6  Social Science Research Solutions (SSRS)                 Data Scientist   \n",
       "\n",
       "                                         Job_Summary  \\\n",
       "0  Is seeking candidates for a Senior Data Scient...   \n",
       "1  The Center for Forensic Science Research and E...   \n",
       "2  McKean Defense is a Naval Life Cycle Managemen...   \n",
       "3  Janssen Research & Development is a world-clas...   \n",
       "4  Are you passionate about forecasting?Do you de...   \n",
       "5  About The Data Science Group.The Data Science ...   \n",
       "6  SSRS, a leading data-driven survey research an...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Philadelphia, PA 19112 (Marconi Plaza-Packer P...   \n",
       "1                                   Willow Grove, PA   \n",
       "2                                   Philadelphia, PA   \n",
       "3                                   Spring House, PA   \n",
       "4                                   Philadelphia, PA   \n",
       "5     Philadelphia, PA 19107 (City Center East area)   \n",
       "6                                     Glen Mills, PA   \n",
       "\n",
       "                                             JD_Link  \\\n",
       "0  https://www.indeed.com/viewjob??jk=4be3251985c...   \n",
       "1  https://www.indeed.com/viewjob??jk=5478fd9dd29...   \n",
       "2  https://www.indeed.com/viewjob??jk=85204fc1a1d...   \n",
       "3  https://www.indeed.com/viewjob??jk=b8946db7aad...   \n",
       "4  https://www.indeed.com/viewjob??jk=67a1dad2fca...   \n",
       "5  https://www.indeed.com/viewjob??jk=5f7754112b0...   \n",
       "6  https://www.indeed.com/viewjob??jk=6b4ec424a41...   \n",
       "\n",
       "                                     job_description  \n",
       "0  TDI Technologies, Inc. is seeking candidates f...  \n",
       "1  Title: Epidemiologist/ Data Scientist\\n\\nDepar...  \n",
       "2  McKean Defense is a Naval Life Cycle Managemen...  \n",
       "3  Janssen Research & Development is a world-clas...  \n",
       "4  Are you passionate about forecasting? Do you d...  \n",
       "5  Description\\nAbout The Data Science Group\\nThe...  \n",
       "6  SSRS Data Scientist\\nSSRS, a leading data-driv...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_company_df = pd.merge(full_company_df, all_company_df, on = ['JD_Link'], how = 'left')\n",
    "full_company_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing down the final results in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = 'E:/personal_projects/indeed_ds_job_scrapping/indeed_scrapping_results'\n",
    "os.chdir(results_path)\n",
    "time1 = time.strftime(\"%m%d-%H%M\")\n",
    "folder_name = \"all_cities_data_science_jobs\" + time1\n",
    "writer = ExcelWriter(folder_name+ '_update.xlsx')\n",
    "full_company_df.to_excel(writer, 'all_summary_roles', index = False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Automated Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = ['Philadelphia','San+Francisco', 'New+York', 'California', 'Houston', 'Boston', 'Chicago', 'Seattle', 'Austin', 'Maryland']\n",
    "\n",
    "all_company_final_summary = pd.DataFrame()\n",
    "\n",
    "for city_index in range(0,len(city_list)):\n",
    "    \n",
    "    city_name = city_list[city_index]\n",
    "    \n",
    "    for page_index in range(1,9):\n",
    "        #page_index = 1\n",
    "        number = page_index * 10\n",
    "        \n",
    "        original_html = 'https://www.indeed.com/jobs?q=data+scientist+$65,000&l='+city_name+'&start='+str(number)\n",
    "        \n",
    "        urlpage =  str(original_html)\n",
    "        page = urllib.request.urlopen(urlpage)\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        \n",
    "        #Extracting all links\n",
    "        \n",
    "            \n",
    "        #Finding meaning of words\n",
    "        title = soup.findAll(attrs={\"class\":\"headline\"})\n",
    "        word_meaning = str(title)\n",
    "        \n",
    "        #Loop to extract job roles present on page\n",
    "        all_links = []\n",
    "        all_roles = []\n",
    "        role_list = soup.findAll('div', attrs={'class':'title'})\n",
    "        for i in range(0,len(role_list)):\n",
    "            #i = 0\n",
    "            s = str(role_list[i])\n",
    "            start = 'href='\n",
    "            end = ' id='\n",
    "            link = s[s.find(start)+len(start):s.rfind(end)]\n",
    "            link = link.replace('\"', \"\")\n",
    "            all_links.append(link)\n",
    "            title_name = str(role_list[i].text)\n",
    "            title_name = title_name.strip()\n",
    "            all_roles.append(title_name)\n",
    "        \n",
    "        \n",
    "        all_podcast_links = all_links\n",
    "        \n",
    "        all_podcast_links = [i.split('-')[-1] for i in all_podcast_links]\n",
    "        \n",
    "        modified_links = []\n",
    "        for i in range(0,len(all_podcast_links)):\n",
    "            main_link_text = all_podcast_links[i]\n",
    "            string_find = '/rc/clk'\n",
    "            if(main_link_text.find(string_find) == -1):\n",
    "                main_link_text = '/rc/clk?jk=' + main_link_text\n",
    "                text_replace = \"?fccid=\"\n",
    "                main_link_text = main_link_text.replace(text_replace, '&amp;fccid=')\n",
    "                print('Link modified for link number', i)\n",
    "            else:\n",
    "                main_link_text = main_link_text\n",
    "            modified_links.append(main_link_text)\n",
    "        \n",
    "        text_delete = '/rc/clk'\n",
    "        all_podcast_links = [w.replace(text_delete,\"\") for w in modified_links]\n",
    "        text_replace = \"/jobs/\"\n",
    "        all_podcast_links = [w.replace(text_replace,\"&t=\") for w in all_podcast_links]\n",
    "        text_to_add = 'https://www.indeed.com/viewjob?'\n",
    "        final_links = [text_to_add+s for s in all_podcast_links]\n",
    "        text_replace = \"/viewjob?/company/\"\n",
    "        final_links = [w.replace(text_replace,\"/company/\") for w in final_links]\n",
    "        \n",
    "        \n",
    "        all_companies = []\n",
    "        company_list = soup.findAll('span', attrs={'class':'company'})\n",
    "        for i in range(0,len(company_list)):\n",
    "            #i = 2\n",
    "            comp_name = str(company_list[i].text)\n",
    "            comp_name = comp_name.strip()\n",
    "            all_companies.append(comp_name)\n",
    "            \n",
    "        all_locations = []\n",
    "        location_list = soup.findAll('span', attrs={'class':'location accessible-contrast-color-location'})\n",
    "        for i in range(0,len(location_list)):\n",
    "            #i = 2\n",
    "            loc_name = str(location_list[i].text)\n",
    "            loc_name = loc_name.strip()\n",
    "            all_locations.append(loc_name)\n",
    "        \n",
    "        all_job_summary = []\n",
    "        job_summary_list = soup.findAll('div', attrs={'class':'summary'})\n",
    "        for i in range(0,len(location_list)):\n",
    "            #i = 2\n",
    "            job_summary = str(job_summary_list[i].text)\n",
    "            job_summary = job_summary.strip()\n",
    "            all_job_summary.append(job_summary)\n",
    "            \n",
    "           \n",
    "        full_company_df = pd.DataFrame(\n",
    "            {'Company_Name': all_companies,\n",
    "             'Role': all_roles,\n",
    "             'Job_Summary': all_job_summary,\n",
    "             'Location' :all_locations, \n",
    "             'JD_Link' :final_links\n",
    "            })\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_company_df = pd.DataFrame()\n",
    "        ###Opening links present in the page###Opening links present in the page###Opening links present in the page###Opening links present in the page###Opening links present in the page\n",
    "        ###Opening links present in the page###Opening links present in the page###Opening links present in the page###Opening links present in the page###Opening links present in the page\n",
    "        for i in range(0, len(full_company_df)):\n",
    "            #i = 0\n",
    "            new_link = full_company_df['JD_Link'][i]\n",
    "            urlpage =  str(new_link)\n",
    "            #main_word = top_10pages[i]\n",
    "            # query the website and return the html to the variable 'page'\n",
    "            page = urllib.request.urlopen(urlpage)\n",
    "            # parse the html using beautiful soup and store in variable 'soup'\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            \n",
    "            script = soup.find('script')\n",
    "            \n",
    "            #company_name = soup.select('h4.jobsearch-CompanyReview--heading')[0].text.strip()\n",
    "        \n",
    "            divs = soup.find_all('div',attrs={\"id\" : \"jobDescriptionText\"})\n",
    "            for d in divs:\n",
    "                job_description = str(d.text)\n",
    "            #Creating master_Dataframe\n",
    "            \n",
    "            master_df = pd.DataFrame({'JD_Link' : urlpage, 'job_description' : job_description}, index = [0])\n",
    "            all_company_df = all_company_df.append(master_df)\n",
    "            print('JD extracted for ', (i+1), \"out of -\", len(full_company_df))\n",
    "        \n",
    "        ####Rough below####Rough below####Rough below####Rough below####Rough below####Rough below\n",
    "        ####Rough below####Rough below####Rough below####Rough below####Rough below####Rough below\n",
    "        ####Rough below####Rough below####Rough below####Rough below####Rough below####Rough below\n",
    "        \n",
    "        full_company_df = pd.merge(full_company_df, all_company_df, on = ['JD_Link'], how = 'left')\n",
    "        all_company_final_summary = all_company_final_summary.append(full_company_df)\n",
    "        print('Page Number Done - ', (page_index+1), \"out of -\", 10, 'for city  =', city_name)\n",
    "\n",
    "\n",
    "\n",
    "results_path = 'D:/web scrapping/indeed_job_scrapping/city_wise_results'\n",
    "os.chdir(results_path)\n",
    "time1 = time.strftime(\"%m%d-%H%M\")\n",
    "folder_name = \"all_cities_data_science_jobs\" + time1\n",
    "writer = ExcelWriter(folder_name+ '_update.xlsx')\n",
    "all_company_final_summary.to_excel(writer, 'all_summary_roles', index = False)\n",
    "#survey_cartocar.to_excel(writer , 'merged_survey_cartocar')\n",
    "writer.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
